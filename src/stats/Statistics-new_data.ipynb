{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234a5646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.stats import kstest, ttest_rel\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8d5da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path('/Users/jdafflon/Code/bblocks-phenotypes/outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa89eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype_path= Path(\"/Users/jdafflon/Code/bblocks-phenotypes/data/HCP/brainblocks-0.1.0/phenotype\")\n",
    "data_type='numeric'\n",
    "hcp_phenotype = pd.read_csv(phenotype_path / f'phenotype_measures_imputation-imputed_numeric_validation_zscored.txt',\n",
    "                                  index_col='participant')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30584e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_phenotype.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e628a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_list = [ 'CardSort_AgeAdj','CardSort_Unadj','DDisc_AUC_200', 'DDisc_AUC_40K', 'Emotion_Task_Face_Acc',\n",
    "              'Flanker_AgeAdj', 'Flanker_Unadj','IWRD_TOT', 'ListSort_AgeAdj', 'ListSort_Unadj',\n",
    "              'PMAT24_A_CR', 'PicSeq_AgeAdj', 'PicSeq_Unadj','ProcSpeed_AgeAdj', 'ProcSpeed_Unadj',\n",
    "              'Relational_Task_Acc', 'SCPT_SEN','SCPT_SPEC','Social_Task_Perc_Random', 'Social_Task_Perc_TOM',\n",
    "              'VSPLOT_TC', 'WM_Task_Acc', 'ER40ANG', 'ER40FEAR', 'ER40NOE', 'ER40SAD', 'ER40_CR', 'ER40_CRT']\n",
    "\n",
    "# list of indices with the disired task columns\n",
    "task_pheno = hcp_phenotype.columns.get_indexer(task_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5312d86c",
   "metadata": {},
   "source": [
    "## How predictable are phenotypes from HBN and how do they compare to the predictability of the other datasets we analysed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f51f938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "#hcp predictions\n",
    "\n",
    "dataset = 'HCP'\n",
    "hcp_predictions = np.load(output_path / dataset / f'regress_covariates_predictions-{dataset.lower()}_test/predictions.npz', allow_pickle=True)\n",
    "\n",
    "dataset = 'PNC'\n",
    "pnc_predictions = np.load(output_path / dataset / f'regress_covariates_predictions-{dataset.lower()}_test/predictions.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777c7d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_predictions['y_val_predicted'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbb908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data to one dimension\n",
    "hcp = hcp_predictions['y_val_predicted'].reshape(-1)\n",
    "pnc = pnc_predictions['y_val_predicted'].reshape(-1)\n",
    "print(f'hcp shape {hcp.shape} and pnc shape {pnc.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f71a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "ax1.hist(hcp, density=True, label='hcp', color='green')\n",
    "ax2.hist(pnc, density=True, label='pnc', color='blue')\n",
    "ax1.set_ylabel('Probability Density')\n",
    "ax2.legend();\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b31b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kgm_test = kstest(pnc, hcp)\n",
    "kgm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11794cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the average over bootstrap\n",
    "hcp_mean = hcp_predictions['y_val_predicted'].mean(axis=0).reshape(-1)\n",
    "print(hcp_mean.shape)\n",
    "pnc_mean = pnc_predictions['y_val_predicted'].mean(axis=0).reshape(-1)\n",
    "\n",
    "kgm_test = kstest(hcp_mean, pnc_mean)\n",
    "kgm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db79071",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, sharex=True)\n",
    "ax1.hist(hcp_mean, density=True, label='hcp', color='green')\n",
    "sns.kdeplot(hcp_mean,color='black', ax=ax1, cut=0)\n",
    "ax2.hist(pnc_mean, density=True, label='pnc', color='blue')\n",
    "ax1.set_ylabel('Probability Density')\n",
    "sns.kdeplot(pnc_mean,color='black', ax=ax2, cut=0)\n",
    "ax2.legend();\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a07dd8",
   "metadata": {},
   "source": [
    "### Get only values for HCP that are related to task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af93ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_mean = hcp_predictions['y_val_predicted'].mean(axis=0)\n",
    "hcp_mean2 = hcp_mean[:, task_pheno].reshape(-1)\n",
    "print(hcp_mean2.shape)\n",
    "\n",
    "pnc_mean = pnc_predictions['y_val_predicted'].mean(axis=0).reshape(-1)\n",
    "\n",
    "kgm_test = kstest(hcp_mean2, pnc_mean)\n",
    "kgm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99162b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, sharex=True)\n",
    "ax1.hist(hcp_mean2, density=True, label='hcp', color='green')\n",
    "sns.kdeplot(hcp_mean2,color='black', ax=ax1, cut=0)\n",
    "ax2.hist(pnc_mean, density=True, label='pnc', color='blue')\n",
    "ax1.set_ylabel('Probability Density')\n",
    "sns.kdeplot(pnc_mean,color='black', ax=ax2, cut=0)\n",
    "ax2.legend();\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f729dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check with the sorted predictions (not the all predictions)\n",
    "#hcp_mean = hcp_predictions['y_val_predicted'].mean(axis=0)\n",
    "#hcp_mean2 = hcp_mean[:, idx_sorted].reshape(-1)\n",
    "#print(hcp_mean2.shape)\n",
    "\n",
    "#pnc_mean = pnc_predictions['y_val_predicted'].mean(axis=0).reshape(-1)\n",
    "\n",
    "#kgm_test = kstest(hcp_mean2, pnc_mean)\n",
    "#print(kgm_test)\n",
    "\n",
    "#fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, sharex=True)\n",
    "#ax1.hist(hcp_mean2, density=True, label='hcp', color='green')\n",
    "#sns.kdeplot(hcp_mean2,color='black', ax=ax1, cut=0)\n",
    "#ax2.hist(pnc_mean, density=True, label='pnc', color='blue')\n",
    "#ax1.set_ylabel('Probability Density')\n",
    "#sns.kdeplot(pnc_mean,color='black', ax=ax2, cut=0)\n",
    "#ax2.legend();\n",
    "#ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d77de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the kstest: The null hypothesis is that the two distributions are identical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e8ef9b",
   "metadata": {},
   "source": [
    "## How does controlling for age/sex confounds impact the phenotypes prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd753e00",
   "metadata": {},
   "source": [
    "### HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e2beb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hcp predictions\n",
    "dataset = 'HCP'\n",
    "data_regressed = np.load(output_path / dataset / f'regress_covariates_predictions-{dataset.lower()}_test/predictions.npz', allow_pickle=True)\n",
    "data_no_regress = np.load(output_path / dataset / f'no_regress_covariates_predictions-{dataset.lower()}_raw_targets/predictions.npz', allow_pickle=True)\n",
    "regressed = data_regressed['y_val_predicted']\n",
    "no_regress = data_no_regress['y_val_predicted']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d416b682",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regressed.shape, no_regress.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ec396a",
   "metadata": {},
   "source": [
    "### compute correlation with the true valeus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658fce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repetitions = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df43f229",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_regressed = np.zeros((n_repetitions, regressed.shape[2]))\n",
    "corr_no_regress = np.zeros((n_repetitions, regressed.shape[2]))\n",
    "for bootstrap in range(regressed.shape[0]):\n",
    "    for target in range(regressed.shape[2]):\n",
    "        corr_regressed[bootstrap, target] = pearsonr(regressed[bootstrap, :, target], data_regressed['y_val_true'][bootstrap, :, target])[0]\n",
    "        corr_no_regress[bootstrap, target] = pearsonr(no_regress[bootstrap, :, target], data_no_regress['y_val_true'][bootstrap, :, target])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e1616",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr_regressed.shape, corr_no_regress.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ba4add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform values into fisher z-transforms\n",
    "z_transformed_correlations_regressed = np.arctanh(corr_regressed)\n",
    "z_transformed_correlations_no_regress = np.arctanh(corr_no_regress)\n",
    "\n",
    "# take the average value over repetitions\n",
    "mean_corr_regressed = z_transformed_correlations_regressed.mean(axis=0)\n",
    "mean_corr_no_regress = z_transformed_correlations_no_regress.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eae3450",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_corr_no_regress.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815fcc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = mean_corr_no_regress - mean_corr_regressed\n",
    "cohensd = difference.mean()/difference.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53aae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and std for the regressed an not regressed\n",
    "print(f\"difference: {difference.mean():.3f}, ({difference.std():.3f})\")\n",
    "\n",
    "print(f\"Cohens D: {cohensd:3.f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d89e9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_rel(mean_corr_regressed, mean_corr_no_regress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35acff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which phenotype is the most predictive?\n",
    "hcp_idx = np.argmax(mean_corr_regressed)\n",
    "hcp_phenotype.columns[hcp_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15410371",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa4a5c9",
   "metadata": {},
   "source": [
    "## PNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fa3ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'PNC'\n",
    "data_regressed = np.load(output_path / dataset / f'regress_covariates_predictions-{dataset.lower()}_test/predictions.npz', allow_pickle=True)\n",
    "data_no_regress = np.load(output_path / dataset / f'no_regress_covariates_predictions-{dataset.lower()}_raw_targets/predictions.npz', allow_pickle=True)\n",
    "regressed = data_regressed['y_val_predicted']\n",
    "no_regress = data_no_regress['y_val_predicted']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d35418",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regressed.shape, no_regress.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0795f7d8",
   "metadata": {},
   "source": [
    "### compute the correlation with the true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84b44e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_regressed = np.zeros((100, regressed.shape[2]))\n",
    "corr_no_regress = np.zeros((100, regressed.shape[2]))\n",
    "for bootstrap in range(regressed.shape[0]):\n",
    "    for target in range(regressed.shape[2]):\n",
    "        corr_regressed[bootstrap, target] = pearsonr(regressed[bootstrap, :, target], data_regressed['y_val_true'][bootstrap, :, target])[0]\n",
    "        corr_no_regress[bootstrap, target] = pearsonr(no_regress[bootstrap, :, target], data_no_regress['y_val_true'][bootstrap, :, target])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7da1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform values into fisher z-transforms\n",
    "z_transformed_correlations_regressed = np.arctanh(corr_regressed)\n",
    "z_transformed_correlations_no_regress = np.arctanh(corr_no_regress)\n",
    "\n",
    "# take the average value over repetitions\n",
    "mean_corr_regressed = z_transformed_correlations_regressed.mean(axis=0)\n",
    "mean_corr_no_regress = z_transformed_correlations_no_regress.mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c384cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#positive t-value shows that the mean of the first group is higher\n",
    "ttest_rel(mean_corr_regressed, mean_corr_no_regress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b4281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean\n",
    "inverse_mean_corr_regressed = np.tanh(mean_corr_regressed)\n",
    "print(f\"{inverse_mean_corr_regressed.mean():.3f} \\pm {inverse_mean_corr_regressed.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5850801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean\n",
    "inverse_mean_no_corr_regressed = np.tanh(mean_corr_no_regress)\n",
    "print(f\"{inverse_mean_no_corr_regressed.mean():.3f} \\pm {inverse_mean_no_corr_regressed.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dec6bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load column information for PNC\n",
    "phenotype_path= Path(\"/Users/jdafflon/Code/bblocks-phenotypes/data/PNC/brainblocks-0.1.0/phenotype\")\n",
    "data_type='numeric'\n",
    "pnc_phenotype = pd.read_csv(phenotype_path / f'phenotype_measures_imputation-imputed_numeric_validation_zscored.txt',\n",
    "                                  index_col='participant')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381508c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which phenotype is the most predictive?\n",
    "pnc_idx = np.argmax(mean_corr_regressed)\n",
    "pnc_phenotype.columns[pnc_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f07d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnc_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b6e137",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = mean_corr_no_regress - mean_corr_regressed\n",
    "cohens_d = difference.mean()/ difference.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b438d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and std for the regressed an not regressed\n",
    "print(f\"difference: {difference.mean():.3f}, ({difference.std():.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869fe7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Cohens D: {cohens_d:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024332da",
   "metadata": {},
   "source": [
    "## Can we obtain more predictable phenotypes if we use a linear transformation to latent phenotypes (SVD) on HBN? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133724b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp, zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ac4c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_latent.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5237d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hcp predictions\n",
    "dataset = 'HCP'\n",
    "data_latent = np.load(output_path / dataset / f'regress_covariates_predictions-{dataset.lower()}-latent_targets-zscore_column/predictions.npz', allow_pickle=True)\n",
    "data_pheno = np.load(output_path / dataset / f'regress_covariates_predictions-{dataset.lower()}_test/predictions.npz', allow_pickle=True)\n",
    "# take the mean over repetitions\n",
    "predicted_latent = data_latent['y_val_predicted'].mean(axis=0)\n",
    "predicted_pheno = data_pheno['y_val_predicted'].mean(axis=0)\n",
    "\n",
    "# take the mean over repetitions\n",
    "true_latent = data_latent['y_val_true'].mean(axis=0)\n",
    "true_pheno = data_pheno['y_val_true'].mean(axis=0)\n",
    "\n",
    "# select only the first phenotype for the latent and the most predictable phenotype\n",
    "predicted_latent = predicted_latent[:, 0]\n",
    "predicted_pheno = predicted_pheno[:, hcp_idx]\n",
    "\n",
    "true_latent = true_latent[:, 0]\n",
    "true_pheno = true_pheno[:, hcp_idx]\n",
    "\n",
    "# z-score the results\n",
    "true_latent = zscore(true_latent)\n",
    "true_pheno = zscore(true_pheno)\n",
    "predicted_latent = zscore(predicted_latent)\n",
    "predicted_pheno = zscore(predicted_pheno)\n",
    "\n",
    "\n",
    "## Compute the error matrix\n",
    "latent_err = predicted_latent - true_latent\n",
    "pheno_err = predicted_pheno - true_pheno\n",
    "\n",
    "## Subract both error matrices\n",
    "error_matrix = pheno_err - latent_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5949d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_latent['y_val_predicted'].shape, predicted_pheno.shape, error_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f06fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_latent['y_val_true'][:8, 2, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00cb5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_latent['y_val_predicted'][:8, 2, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2283b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pheno['y_val_true'][:8, 2, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff63b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pheno['y_val_predicted'][:8, 2, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f9b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_latent['y_val_true'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5452ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize error matrix\n",
    "plt.scatter(range(len(error_matrix)), np.expand_dims(error_matrix, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3c334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we obtain more predictable phenotypes if we use a linear transformation to latent phenotypes (SVD) on HBN? \n",
    "# The assumption is that the mean error would be 0 if they are the same\n",
    "# null hypothesis: sample of independent observations a is equal to the given population mean, popmean.\n",
    "population_mean = 0\n",
    "ttest_1samp(error_matrix, population_mean, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad896712",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'HCP'\n",
    "latent_dat = np.load(output_path / dataset / f'regress_covariates_predictions-{dataset.lower()}-latent_targets-zscore_column/predictions.npz', allow_pickle=True)\n",
    "phenotype_dat = np.load(output_path / dataset / f'regress_covariates_predictions-{dataset.lower()}_test/predictions.npz', allow_pickle=True)\n",
    "\n",
    "n_bootstraps = latent_dat['y_val_true'].shape[0]\n",
    "n_subs = latent_dat['y_val_true'].shape[1]\n",
    "n_phenotypes = latent_dat['y_val_true'].shape[-1]\n",
    "l_y_val_true = latent_dat['y_val_true']\n",
    "l_y_val_pred = latent_dat['y_val_predicted']\n",
    "p_y_val_true = phenotype_dat['y_val_true']\n",
    "p_y_val_pred = phenotype_dat['y_val_predicted']\n",
    "\n",
    "l_y_val_true_z = zscore(l_y_val_true, axis=1)\n",
    "l_y_val_pred_z = zscore(l_y_val_pred, axis=1)\n",
    "l_y_val_dif = np.abs(l_y_val_pred_z - l_y_val_true_z).mean(0)\n",
    "top_latent_idx = (l_y_val_dif.mean(0) == l_y_val_dif.mean(0).min()).nonzero()[0][0]\n",
    "top_latent_dif = l_y_val_dif[:, top_latent_idx]\n",
    "\n",
    "p_y_val_true_z = zscore(p_y_val_true, axis=1)\n",
    "p_y_val_pred_z = zscore(p_y_val_pred, axis=1)\n",
    "p_y_val_dif = np.abs(p_y_val_pred_z - p_y_val_true_z).mean(0)\n",
    "top_pheno_idx = (p_y_val_dif.mean(0) == p_y_val_dif.mean(0).min()).nonzero()[0][0]\n",
    "top_pheno_dif = p_y_val_dif[:, top_pheno_idx]\n",
    "\n",
    "top_dif = (top_pheno_dif - top_latent_dif)\n",
    "\n",
    "print(f'latent MAE (std): {top_latent_dif.mean():0.3f} ({top_latent_dif.std():0.3f})')\n",
    "print(f'pheno  MAE (std): {top_pheno_dif.mean():0.3f} ({top_pheno_dif.std():0.3f})')\n",
    "print(f'dif  MAE (std): {top_dif.mean():0.3f} ({top_dif.std():0.3f})')\n",
    "print(f\"Cohen's d: {top_dif.mean() / top_dif.std()}\")\n",
    "print(ttest_rel(top_pheno_dif, top_latent_dif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b58d01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How different are the distributions between latent and phenotype? Do they ahve the same range of values?\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, sharex=True)\n",
    "ax1.hist(predicted_latent.reshape(-1), density=True, label='latent', color='green')\n",
    "sns.kdeplot(predicted_latent.reshape(-1),color='black', ax=ax1, cut=0)\n",
    "\n",
    "\n",
    "sns.kdeplot(predicted_pheno, color='black', ax=ax2, cut=0)\n",
    "ax2.hist(predicted_pheno, density=True, label='pheno', color='green')\n",
    "ax1.set_ylabel('Probability Density')\n",
    "ax2.legend();\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9d3d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How different are the distributions between latent and phenotype? Do they ahve the same range of values?\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, sharex=True)\n",
    "ax1.hist(true_latent.reshape(-1), density=True, label='latent', color='green')\n",
    "sns.kdeplot(true_latent.reshape(-1),color='black', ax=ax1, cut=0)\n",
    "\n",
    "\n",
    "sns.kdeplot(true_pheno, color='black', ax=ax2, cut=0)\n",
    "ax2.hist(true_pheno, density=True, label='pheno', color='green')\n",
    "ax1.set_ylabel('Probability Density')\n",
    "ax2.legend();\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214dd6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_pheno.min(), predicted_latent.min())\n",
    "print(predicted_pheno.max(), predicted_latent.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0290fab0",
   "metadata": {},
   "source": [
    "### PNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d40e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'PNC'\n",
    "\n",
    "latent_dat = np.load(output_path / dataset / f'regress_covariates_predictions-{dataset.lower()}-latent_targets-zscore_column/predictions.npz', allow_pickle=True)\n",
    "phenotype_dat = np.load(output_path / dataset / f'regress_covariates_predictions-{dataset.lower()}_test/predictions.npz', allow_pickle=True)\n",
    "\n",
    "n_bootstraps = latent_dat['y_val_true'].shape[0]\n",
    "n_subs = latent_dat['y_val_true'].shape[1]\n",
    "n_phenotypes = latent_dat['y_val_true'].shape[-1]\n",
    "l_y_val_true = latent_dat['y_val_true']\n",
    "l_y_val_pred = latent_dat['y_val_predicted']\n",
    "p_y_val_true = phenotype_dat['y_val_true']\n",
    "p_y_val_pred = phenotype_dat['y_val_predicted']\n",
    "\n",
    "l_y_val_true_z = zscore(l_y_val_true, axis=1)\n",
    "l_y_val_pred_z = zscore(l_y_val_pred, axis=1)\n",
    "l_y_val_dif = np.abs(l_y_val_pred_z - l_y_val_true_z).mean(0)\n",
    "top_latent_idx = (l_y_val_dif.mean(0) == l_y_val_dif.mean(0).min()).nonzero()[0][0]\n",
    "top_latent_dif = l_y_val_dif[:, top_latent_idx]\n",
    "\n",
    "p_y_val_true_z = zscore(p_y_val_true, axis=1)\n",
    "p_y_val_pred_z = zscore(p_y_val_pred, axis=1)\n",
    "p_y_val_dif = np.abs(p_y_val_pred_z - p_y_val_true_z).mean(0)\n",
    "top_pheno_idx = (p_y_val_dif.mean(0) == p_y_val_dif.mean(0).min()).nonzero()[0][0]\n",
    "top_pheno_dif = p_y_val_dif[:, top_pheno_idx]\n",
    "\n",
    "top_dif = (top_pheno_dif - top_latent_dif)\n",
    "\n",
    "print(f'latent MAE (std): {top_latent_dif.mean():0.3f} ({top_latent_dif.std():0.3f})')\n",
    "print(f'pheno  MAE (std): {top_pheno_dif.mean():0.3f} ({top_pheno_dif.std():0.3f})')\n",
    "print(f'dif  MAE (std): {top_dif.mean():0.3f} ({top_dif.std():0.3f})')\n",
    "print(f\"Cohen's d: {top_dif.mean() / top_dif.std()}\")\n",
    "print(ttest_rel(top_pheno_dif, top_latent_dif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8a651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hcp predictions\n",
    "dataset = 'PNC'\n",
    "data_latent = np.load(output_path / dataset / f'regress_covariates_predictions-{dataset.lower()}-latent_targets-zscore_column/predictions.npz', allow_pickle=True)\n",
    "data_pheno = np.load(output_path / dataset / f'regress_covariates_predictions-{dataset.lower()}_test/predictions.npz', allow_pickle=True)\n",
    "# take the mean over repetitions\n",
    "predicted_latent = data_latent['y_val_predicted'].mean(axis=0)\n",
    "predicted_pheno = data_pheno['y_val_predicted'].mean(axis=0)\n",
    "\n",
    "# take the mean over repetitions\n",
    "true_latent = data_latent['y_val_true'].mean(axis=0)\n",
    "true_pheno = data_pheno['y_val_true'].mean(axis=0)\n",
    "\n",
    "# select only the first phenotype for the latent and the most predictable phenotype\n",
    "predicted_latent = predicted_latent[:, 0]\n",
    "predicted_pheno = predicted_pheno[:, pnc_idx]\n",
    "\n",
    "true_latent = true_latent[:, 0]\n",
    "true_pheno = true_pheno[:, pnc_idx]\n",
    "\n",
    "## Compute the error matrix\n",
    "latent_err = predicted_latent - true_latent\n",
    "pheno_err = predicted_pheno - true_pheno\n",
    "\n",
    "## Subract both error matrices\n",
    "error_matrix = pheno_err - latent_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65239be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_latent['y_train_predicted'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbae050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize error matrix\n",
    "plt.scatter(range(len(error_matrix)), np.expand_dims(error_matrix, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456b702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac71376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we obtain more predictable phenotypes if we use a linear transformation to latent phenotypes (SVD) on HBN? \n",
    "# The assumption is that the mean error would be 0 if they are the same\n",
    "# null hypothesis: sample of independent observations a is equal to the given population mean, popmean.\n",
    "# the p-value is smaller so you can reject the Null-hypothesis\n",
    "population_mean = 0\n",
    "ttest_1samp(error_matrix, population_mean, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63ca98e",
   "metadata": {},
   "source": [
    "# Is there any changes on the reconstructions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188eee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autorank import autorank, plot_stats, create_report, latex_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1e3b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the results and put it in the correct shape to for the autorank test\n",
    "def get_data_compute_correlation(data_path, n_repetitions, predicted_val, true_val):\n",
    "    \n",
    "    corr = np.zeros((n_repetitions, predicted_val.shape[2]))\n",
    "    for bootstrap in range(predicted_val.shape[0]):\n",
    "        for target in range(predicted_val.shape[2]):\n",
    "            corr[bootstrap, target] = pearsonr(predicted_val[bootstrap, :, target], true_val[bootstrap, :, target])[0]\n",
    "            \n",
    "    # transform values into fisher z-transforms\n",
    "    z_transformed_correlations = np.arctanh(corr)\n",
    "\n",
    "    # take the average value over repetitions\n",
    "    mean_corr = z_transformed_correlations.mean(axis=0)\n",
    "    return mean_corr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fd45c9",
   "metadata": {},
   "source": [
    "## HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816e9cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repetitions = 100\n",
    "dataset = 'HCP'\n",
    "data_df = pd.DataFrame(columns=['1 comp', '2 comp', '3 comp', '4 comp', '5 comp', 'all'])\n",
    "\n",
    "file_name = {'1 comp': \"001\", '2 comp': \"002\", '3 comp': \"003\", '4 comp': \"004\", '5 comp': \"005\", 'all': \"083\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a8b4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results for all components\n",
    "for key in file_name:\n",
    "    data_path = output_path / dataset / f\"regress_covariates_predictions-{dataset.lower()}-latent_targets_svd-zscore_y_val_orig_column-{file_name[key]}_component/predictions.npz\"\n",
    "    data = np.load(data_path, allow_pickle=True)\n",
    "\n",
    "    predicted_val = data['y_val_predicted']\n",
    "    true_val = data['y_val_true']\n",
    "\n",
    "    data_df[key] = get_data_compute_correlation(data_path, n_repetitions, predicted_val, true_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c07b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedd38f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save datafarme to send to Dylan\n",
    "data_df.to_csv('hcp_anova.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99502a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pingouin import rm_anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cf86a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = rm_anova(data_df, effsize='n2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2950f1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score = np.sqrt(res['n2'] / (1-res['n2']))\n",
    "print(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f0cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_result = autorank(data_df, alpha=0.05, verbose=False, order='ascending')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eeb9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b7a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_report(hcp_result)\n",
    "latex_table(hcp_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad75fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stats(hcp_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d44cba",
   "metadata": {},
   "source": [
    "## PNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fa8574",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repetitions = 100\n",
    "dataset = 'PNC'\n",
    "data_df = pd.DataFrame(columns=['1 comp', '2 comp', '3 comp', '4 comp', '5 comp', 'all'])\n",
    "\n",
    "file_name = {'1 comp': \"001\", '2 comp': \"002\", '3 comp': \"003\", '4 comp': \"004\", '5 comp': \"005\", 'all': \"039\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7dde15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results for all components\n",
    "for key in file_name:\n",
    "    data_path = output_path / dataset / f\"regress_covariates_predictions-{dataset.lower()}-latent_targets_svd-zscore_y_val_orig_column-{file_name[key]}_component/predictions.npz\"\n",
    "    data = np.load(data_path, allow_pickle=True)\n",
    "\n",
    "    predicted_val = data['y_val_predicted']\n",
    "    true_val = data['y_val_true']\n",
    "\n",
    "    data_df[key] = get_data_compute_correlation(data_path, n_repetitions, predicted_val, true_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5510a50c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8aa1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save datafarme to send to Dylan\n",
    "data_df.to_csv('pnc_anova.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4660313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the repeated anova to estimate the eta values\n",
    "res = rm_anova(data_df, effsize='n2')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c022c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the f-score from the eta values\n",
    "f_score = np.sqrt(res['n2'] / (1-res['n2']))\n",
    "print(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d408cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnc_result = autorank(data_df, alpha=0.05, verbose=False, order='ascending')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afde3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stats(pnc_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bbc93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8cb29b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
